:toc:
:toclevels: 5
:toc-placement!:
:source-highlighter: highlight.js
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
:github-repository: https://github.com/WSE-research/OpenAI-API-wrapper-with-moderation
endif::[]

= Hawki API Wrapper (beta)

This is a wrapper for the https://github.com/hawk-digital-environments/HAWKI[HAWKI] framework to support quasi-standard API requests using the https://platform.openai.com/docs/api-reference/introduction[OpenAI API format]. 

---

toc::[]

---

== Building and Running the Application

=== Running locally with Python 3.10+

==== Install dependencies

===== Create a venv environment and run it
To seperate the libraries and their versions from your global pip/python installation, you can use environments that you can tailor for each project. 

To create one: `python -m venv myfirstproject`

To enter it: `source myfirstproject/bin/activate`

For further questions, see https://www.w3schools.com/python/python_virtualenv.asp

===== Install Python dependencies

[source, bash]
----
pip install -r requirements.txt
----

Note: If you are using a virtual environment, make sure to activate it before running the command.

==== Set the environment variables

In the `.env-file`, there are several vars that need to be configured.

```.env
ALLOWED_KEYS=ALLOWED_KEYS # These are the proxy keys to use for auth to the API, choose yourself
PRIMARY_API_KEY=PRIMARY_API_KEY # That's your Hawki Web UI key
SECONDARY_API_KEY=SECONDARY_API_KEY # That's a fallback alternative, if you have only one Hawki Web UI key, insert your Primary Key here, again
PORT=8080 # adjust as you like, not necessary
HAWKI_API_URL=HAWKI_API_URL # the Hawki Web UI endpoint, defaults to https://hawki2.htwk-leipzig.de/api/ai-req
```

==== Run the Application

[source, bash]
----
python wrapper.py
----

After that, you can access the application at http://localhost:8080.

=== Build and run with Docker

==== Build

From within the repository, execute `docker build . -t YOUR_IMAGE_NAME`. As you need to set the environment variables here, too. Either set it in the .env file before building, as described before, or set them as `ENV ALLOWED_KEYS=....` in the Dockerfile, see comments there. A third option is to pass them as environemnt variables when running the container.

==== Running
`docker run YOUR_IMAGE_NAME` and optional ` -e ALLOWED_KEYS=.. ` when you want to pass the env vars here.



=== Exemplary request

The request format follows the OpenAI standard, i.e.:

```json
{
  "model":"gpt-4o",
  "messages":
  [
    {"role":"system","content":"You are Auto Router, a large language model from openrouter.\n\nFormatting Rules:\n- Use Markdown **only when semantically appropriate**. Examples: `inline code`, ```code fences```, tables, and lists.\n- In assistant responses, format file names, directory paths, function names, and class names with backticks (`).\n- For math: use \\( and \\) for inline expressions, and \\[ and \\] for display (block) math."},
    {"role":"user","content":"Whats up?"}
  ]
}
```

=== Trouble-shooting (Cooldowns)
If you face long waiting times for responses, that may be due to the settings of `global_timeout` in ln 141 in HawkiLLM.py. Change that according to your needs. The same applies for cases when responses may take longer due to large prompts. Experiment with it.

== Contribute

We are happy to receive your contributions. 
Please create a pull request or an {github-repository}/issues/new[issue].
As this tool is published under the {github-repository}/blob/main/LICENSE[MIT license], feel free to {github-repository}/fork[fork] it and use it in your own projects.

== Disclaimer

This tool just temporarily stores the image data. 
This tool is provided "as is" and without any warranty, express or implied.
